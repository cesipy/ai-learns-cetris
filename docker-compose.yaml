services: 
# cnn, expert_counter = 1, amount_pieces = 7
# new, reworked reward 17.1
  experiment_1: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm 


# cnn, expert_counter = 2, amount_pieces = 7
# new, reworked reward 17.1
  experiment_2:
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm     

# cnn, expert_counter = 3, amount_pieces = 7
# new, complex reward
  experiment_3: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm     
  
# cnn, expert_counter = 10, amount_pieces = 2
# more max height punishment
  experiment_4: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm

# cnn, expert_counter = 10, amount_pieces = 2
# super simple reward , w piececount, linescleared and game_over
  experiment_5: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm     


  experiment_6: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm     


  experiment_7: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm     

  experiment_8: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm     

  experiment_9: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm    


  
  experiment_cuda1: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm    
    deploy:
      resources: 
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  experiment_cuda2: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm    
    deploy:
      resources: 
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  experiment_cuda3: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm    
    deploy:
      resources: 
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  experiment_cuda4: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm    
    deploy:
      resources: 
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  experiment_cuda5: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm    
    deploy:
      resources: 
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  experiment_cuda6: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm    
    deploy:
      resources: 
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  experiment_cuda7: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm    
    deploy:
      resources: 
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
            

  experiment_cuda8: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm    
    deploy:
      resources: 
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]


  experiment_cuda9: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm    
    deploy:
      resources: 
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
            

  experiment_cuda10: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm    
    deploy:
      resources: 
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  experiment_cuda11: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm    
    deploy:
      resources: 
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
            

  experiment_cuda12: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm    
    deploy:
      resources: 
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]


  experiment_cuda13: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm    
    deploy:
      resources: 
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
            

  experiment_cuda14: 
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-learns-tetris
    # special case for my tetris implementation, from gpt. 
    # currently no visuals
    tty: true          # Allocates a pseudo-TTY
    stdin_open: true   # Keeps stdin open
    environment:
      - TERM=xterm    
    deploy:
      resources: 
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  